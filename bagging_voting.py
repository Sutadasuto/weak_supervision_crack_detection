import tensorflow as tf

tf.compat.v1.disable_eager_execution()

import argparse
import cv2
import importlib
import numpy as np
import os

import data

from distutils.util import strtobool
from tensorflow.keras.optimizers import Adam
import tensorflow.keras.metrics as keras_metrics

from models.available_models import get_models_dict
from callbacks_and_losses import custom_losses

# Used for memory error in RTX2070
physical_devices = tf.config.experimental.list_physical_devices('GPU')
config = tf.config.experimental.set_memory_growth(physical_devices[0], True)

models_dict = get_models_dict()


def get_weight_paths(folder_path):
    models = sorted([f for f in os.listdir(folder_path)
                     if not f.startswith(".") and os.path.isdir(os.path.join(folder_path, f))],
                    key=lambda f: f.lower())
    return [os.path.join(folder_path, model, "results_training_min_val_loss", "%s_best.hdf5" % model) for model in
            models]


def majority_voting(predictions):
    voting = np.sum(predictions, axis=-1) / predictions.shape[-1]
    return np.where(voting > 0.5, 1.0, 0.0)


def consensus_voting(predictions):
    voting = np.sum(predictions, axis=-1)
    return np.where(voting >= float(predictions.shape[-1]), 1.0, 0.0)


def main(args):
    weights = get_weight_paths(args.weights_folder)

    # Here we find to paths to all images from the selected datasets
    image_paths = data.create_image_paths(args.dataset_names, args.dataset_paths)

    input_size = (None, None)

    model = models_dict[args.model]((input_size[0], input_size[1], 1))
    try:
        # Model name should match with the name of a model from
        # https://www.tensorflow.org/api_docs/python/tf/keras/applications/
        # This assumes you used a model with RGB inputs as the first part of your model,
        # therefore your input data should be preprocessed with the corresponding
        # 'preprocess_input' function
        m = importlib.import_module('tensorflow.keras.applications.%s' % model.name)
        rgb_preprocessor = getattr(m, "preprocess_input")
    except ModuleNotFoundError:
        rgb_preprocessor = None

    model.compile(optimizer=Adam(), loss=custom_losses.bce_dsc_loss(),
                  metrics=[custom_losses.dice_coef, 'binary_crossentropy',
                           keras_metrics.Precision(), keras_metrics.Recall()])

    save_to = "results_%s_%s" % ("-".join(args.dataset_names), args.voting_strategy)
    if not os.path.exists(save_to):
        os.makedirs(save_to)
    i = 0
    n = image_paths.shape[1]
    for path in image_paths.transpose():
        print("\rProcessed {}%".format(round(i*100 / n, 1)), end='')
        name = os.path.split(path[1])[-1]
        name, extension = os.path.splitext(name)
        extension = ".png"

        predictions = []
        for m in range(len(weights)):
            model.load_weights(weights[m])
            [im, gt, pred] = data.test_image_from_path(model, path[0], None)
            or_shape = cv2.imread(path[0], cv2.IMREAD_GRAYSCALE).shape
            pred = pred[:or_shape[0], :or_shape[1]]
            predictions.append(np.where(pred > 0.5, 1.0, 0.0))

        decision = majority_voting(
            np.concatenate(predictions, axis=-1)) if args.voting_strategy == "majority" else consensus_voting(
            np.concatenate(predictions, axis=-1))
        cv2.imwrite(os.path.join(save_to, name + extension), 255 * decision)
        i += 1
    print("\rProcessed {}%".format(round(i * 100 / n, 1)))


def parse_args(args=None):
    parser = argparse.ArgumentParser()
    parser.add_argument("-d", "--dataset_names", type=str, nargs="+",
                        help="Must be one of: 'cfd', 'cfd-pruned', 'aigle-rn', 'esar', 'crack500', 'gaps384', "
                             "'cracktree200', 'text'")
    parser.add_argument("-p", "--dataset_paths", type=str, nargs="+",
                        help="Path to the folders or files containing the respective datasets as downloaded from the "
                             "original source.")
    parser.add_argument("-w", "--weights_folder", type=str,
                        help="Path to folder generated by 'train_for_bagging'.")
    parser.add_argument("-m", "--model", type=str, default="uvgg19",
                        help="Network to use. It can be either a name from 'models.available_models.py' or a path to a "
                             "json file.")
    parser.add_argument("-s", "--voting_strategy", type=str, default="majority",
                        help="Either 'majority' or 'consensus' voting..")

    args_dict = parser.parse_args(args)
    for attribute in args_dict.__dict__.keys():
        if args_dict.__getattribute__(attribute) == "None":
            args_dict.__setattr__(attribute, None)
        if args_dict.__getattribute__(attribute) == "True" or args_dict.__getattribute__(attribute) == "False":
            args_dict.__setattr__(attribute, bool(strtobool(args_dict.__getattribute__(attribute))))
    return args_dict


if __name__ == "__main__":
    args = parse_args()
    main(args)
